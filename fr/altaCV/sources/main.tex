%%%%%%%%%%%%%%%%%
% This is an example CV created using altacv.cls (v1.3, 10 May 2020) written by
% LianTze Lim (liantze@gmail.com), based on the
% Cv created by BusinessInsider at http://www.businessinsider.my/a-sample-resume-for-marissa-mayer-2016-7/?r=US&IR=T
%
%% It may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 2003/12/01 or later.
%%%%%%%%%%%%%%%%

%% If you are using \orcid or academicons
%% icons, make sure you have the academicons
%% option here, and compile with XeLaTeX
%% or LuaLaTeX.
% \documentclass[10pt,a4paper,academicons]{altacv}

%% Use the "normalphoto" option if you want a normal photo instead of cropped to a circle

\documentclass[10pt,letter,ragged2e,withhyper]{altacv}

%% AltaCV uses the fontawesome5 and academicon fonts and packages.
%% See http://texdoc.net/pkg/fontawesome5 and http://texdoc.net/pkg/academicons for full list of symbols.
%% You MUST compile with XeLaTeX or LuaLaTeX if you want to use academicons.

% Change the page layout if you need to
\geometry{left=1cm,right=1cm,top=0.8cm,bottom=0.8cm,columnsep=0.75cm}

% The paracol package lets you typeset columns of text in parallel
\usepackage{paracol}


% Change the font if you want to, depending on whether
% you're using pdflatex or xelatex/lualatex
\ifxetexorluatex
  % If using xelatex or lualatex:
  \setmainfont{Lato}
\else
  % If using pdflatex:
  \usepackage[default]{lato}
\fi

% Change the colours if you want to
\definecolor{VividPurple}{HTML}{3E0097}
\definecolor{SlateGrey}{HTML}{2E2E2E}
\definecolor{LightGrey}{HTML}{666666}
\definecolor{LimeGreen}{HTML}{11710E}
\definecolor{Blue}{HTML}{253489}
\definecolor{Teal}{HTML}{109EAA}
\definecolor{Silver}{HTML}{B5B5B5}
\definecolor{DarkPastelRed}{HTML}{450808}
\definecolor{PastelRed}{HTML}{8F0D0D}
\definecolor{GoldenEarth}{HTML}{E7D192}
\definecolor{DarkGreen}{HTML}{303d36}
\definecolor{MyGreen}{HTML}{88A05B}

\colorlet{name}{black}
\colorlet{tagline}{teal}
\colorlet{heading}{teal}
\colorlet{headingrule}{teal}
\colorlet{subheading}{DarkGreen}
\colorlet{accent}{teal}
\colorlet{emphasis}{SlateGrey}
\colorlet{body}{LightGrey}

% Change some fonts, if necessary

% Change the bullets for itemize and rating marker
% for \cvskill if you want to
\renewcommand{\itemmarker}{{\small\textbullet}}
\renewcommand{\ratingmarker}{\faCircle}

\renewcommand{\divider}{\textcolor{body!30}{\hdashrule{\linewidth}{0.6pt}{0.5ex}}\medskip}



%% sample.bib contains your publications

\begin{document}
\newcommand{\cvpart}[1]{\ifstrequal{#1}{}{}{{\small\makebox[0.5\linewidth][l]{~#1}}}}

\name{Dhia Hmila}
\tagline{Data Scientist Senior chez AXA France}\photoR{3.5cm}{photo_light.png}
\photoL{3cm}{qrcode.png}

\personalinfo{%
  \email{dhiahmila@gmail.com}  \phone{+33610201606}  \location{92700, Colombes, France}  \homepage{hmiladhia.github.io}
    \printinfo{\faGithub}{hmiladhia}[https://github.com/hmiladhia]
    \printinfo{\faLinkedin}{dhia-hmila}[https://www.linkedin.com/in/dhia-hmila]
    \printinfo{\faMedium}{Dhia Hmila}[https://dhiahmila.medium.com/]
    \printinfo{\faStackOverflow}{dhia-hmila}[https://stackoverflow.com/users/8655480/dhia-hmila?tab=profile]
  
  % \printinfo{\faPaw}{Hey ho!}
}

\makecvheader

%% Depending on your tastes, you may want to make fonts of itemize environments slightly smaller
\AtBeginEnvironment{itemize}{\small}

%% Set the left/right column width ratio to 6:4.
\columnratio{0.6}

% Start a 2-column paracol. Both the left and right columns will automatically
% break across pages if things get too long.
\begin{paracol}{2}

\cvsection{Expérience Professionnelle}

\cvevent{Data Scientist Senior}{Équipe Data Science \& IA, AXA France}{        
      Juin 2021 - Aujourd'hui
      }{Nanterre, France}

\begin{itemize}
  \item Développement de systèmes d'IA d'extraction d'information basé pour lire des documents (permis de conduire, carte d'identité nationale, etc.). Les modèles construit ont permis de traiter plus de 6 millions documents.
  \item Création d'une gamme de packages Python réutilisables pour le traitement de documents (OCR, détection d'objets, etc.). Les packages sont conçus pour expérimenter rapidement avec différents modèles (Startegy Pattern).
  \item Automatisation de l'indexation de 70\% des documents entrants d'AXA France (flux sinistre) en développant un système d'IA de classification de documents (exposé en tant qu'API).
  \item Élaboration de pipelines Azure ML réutilisables (CT - Continuous Training) pour réentrainer automatiquement les systèmes d'IA et les publier dans le Registre des modèles.
  \item Conception de modèles de pipelines CI/CD Azure DevOps à utiliser dans les projets de l'équipe.
  \item Supervision du processus de recrutement, intégration des nouveaux membres de l'équipe et facilitation du transfert efficace des connaissances.
  \item Coordination du processus d'annotation avec les annotateurs et les experts métiers pour garantir des datasets cohérents et de qualité.
  \item Direction de l'initiative "Python COP" d'AXA, organisant une série d'événements mensuels sur la programmation portant sur des sujets tels que les tests, le web scraping, le packaging, la qualité du code, etc.
  \item Animation d'une série de formations ( sur Python, la manipulation des données avec pandas \& pyspark, les bonnes pratiques de code ) pour plus de 30 collaborateurs d'AXA.
\end{itemize}

\divider
\cvevent{Graduate Program - Data Scientist}{Équipe Data, Fraud, Waste \& Abuse, AXA France}{        
      Mai 2020 - Juin 2021
      }{Nanterre, France}

\begin{itemize}
  \item Conception et développement d'un outil de détection avancée des fraudes, gaspillage et abus piloté par l'IA, agissant à différentes échelles (sinistres, prestataires de santé, bénéficiaires). Cet outil novateur a joué un rôle clé dans la réalisation d'économies dépassant les 150 000 euros en 2022.
  \item Conception et entraînement de divers modèles de détection de fraudes pour repérer les patterns frauduleux, dans le cadre de l'outil de détection des FWA(Fraud, Waste \& Abuse).
\end{itemize}

\divider
\cvevent{Data Scientist}{Shift Technology}{        
      Avril 2019 - Mars 2020
      }{Paris, France}

\begin{itemize}
  \item Mis en œuvre des techniques de Traitement du Langage Naturel (NLP) pour regrouper les notes des gestionnaires de sinistres, en utilisant des méthodes de visualisation avancées afin de déceler et d'identifier les patterns de fraude émergents.
  \item Élaboration de nouveaux modèles d'IA pour la solution de détection de fraude de Shift et déploiement de la solution pour un nouveau client.
\end{itemize}

\divider
\cvevent{Stage de recherche}{U2IS - ENSTA Paris}{        
      Mai 2018 - Août 2018
      }{Palaiseau, France}

\begin{itemize}
  \item Simulation d'un agent dans un environnement artificiel et création d'un dataset d'images où on peut percevoir l'effet de l'oubli catastrophique en utilisant le Raytracing pour rendre des images réalistes..
  \item Évaluation de la méthode "Elastic Parameters Consolidation" proposée par un article de recherche pour remédier à l'oubli catastrophique qui surgit lors de l'apprentissage incrémental.
\end{itemize}



\cvsection{Projets}

\cvevent{\faCube \href{https://github.com/hmiladhia/mlflower}{mlflower: Outil d'orchestration pour les projets MLflow.}}{\cvtag{mlflow}\cvtag{orchestration}\cvtag{experiment-tracking}}{        
      Novembre 2023 - Aujourd'hui
      }{}

Outil d'orchestration de jobs d'entraineemnt basé sur MLflow Projects.


\divider
\cvevent{\faCube \href{https://github.com/hmiladhia/pysira}{pysira: publication de CVs dans différents formats.}}{\cvtag{Github Actions}\cvtag{Jinja2 Templates}\cvtag{jsonschema}}{        
      Février 2023 - Aujourd'hui
      }{}

Outil en ligne de commande permettant d'exporter des CVs au format 'jsonresume' vers différents formats (HTML, TeX, PDF, etc.) et langues (Anglais, Françait, etc..).

\begin{itemize}
      \item Création d'un pipeline CI/CD (Actions Github) pour publier des CV dans différents thèmes, formats et langues.
      \item Ce CV a été créé en utilisant pysira : hmiladhia.github.io, hmiladhia.github.io/cv.pdf, hmiladhia.github.io/fr/kendall ou hmiladhia.github.io/resume.pdf
  \end{itemize}

\divider
\cvevent{\faCube \href{https://pypi.org/project/nbmanips/}{nbmanips: Découper, fusionner et convertir vos Notebooks}}{\cvtag{Jupyter}\cvtag{Databricks}\cvtag{Zeppelin}}{        
      Mai 2021 - Aujourd'hui
      }{}

Un package open-source d'outils de manipulation de Notebooks via des scripts python ou une CLI.


\divider
\cvevent{\faLaptop \href{https://spot-language.onrender.com/}{Spot-Language: Prédiction du language de programmation}}{\cvtag{Classification}\cvtag{Flask}\cvtag{NLP}\cvtag{Compression de Modèles}}{        
    Janvier 2020
  }{}

Spot-Language est un modèle de classification des languages utilisés dans des sources de code.

\begin{itemize}
      \item Construction de dataset d'entrainement provenant de repositories github publiques.
      \item Déploiement d'une application Web pour servir de démo au modèle IA.
  \end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Switch to the right column. This will now automatically move to the second
%% page if the content is too long.
\switchcolumn
\cvsection{A Propos De Moi}
{\small
Je suis un Data Scientist Senior spécialisé dans la détection de fraudes/anomalies 
et la classification de documents. J'ai travaillé sur une panoplie de sujets ML 
dont des sujets Computer Vision ou encore NLP/NLU.
Je possède également une solide expérience autour des pratiques de MLOps,
pour garantir une intégration fluide des modèles dans les environnements de production.

}

\cvsection{Cursus}

\cvevent{Double diplôme d'ingénieur}{\cvpart{\faUserGraduate ENSTA ParisTech }\cvpart{\faUserGraduate  ENIT}}{2016 - 2019}{France - Tunisia}
{\small Spécialisé en \textbf{Intelligence Artificielle}}

\divider
\cvevent{Cycle préparatoire}{\cvpart{\faUserGraduate IPEIT }\cvpart{\faUserGraduate  Esprit Prépa}}{2014 - 2015}{France - Tunisia}
{\small Spécialisé en \textbf{Math \& Physique}}
{\small Rang 10 au concours d'entrée aux écoles d'ingénieurs en Tunisie parmi plus de 3000 candidats.}



\cvsection{Compétences}

\cvsubsection{Intelligence Artificielle}
\cvtag{ Anomaly Detection}
\cvtag{ Tensorflow}
\cvtag{ TFX}
\cvtag{ scikit-learn}
\cvtag{ NLP}
\cvtag{ nltk}
\cvtag{ spaCy}
\cvtag{ Gensim}
\cvtag{ pyod}

\divider
\cvsubsection{Data Wrangling}
\cvtag{ pandas}
\cvtag{ pyspark}
\cvtag{\faDatabase SQL}
\cvtag{ ETL}

\divider
\cvsubsection{Languages de programmation}
\cvtag{\faPython Python}
\cvtag{ Rust}
\cvtag{\faJs JavaScript}
\cvtag{ C/C++}
\cvtag{ C\#}

\divider
\cvsubsection{MLOps}
\cvtag{\faGithub Github Workflows}
\cvtag{\faMicrosoft Azure Pipelines}
\cvtag{\faGitSquare Git}
\cvtag{\faLinux Linux}
\cvtag{\faDocker Docker}
\cvtag{\faMicrosoft Azure ML}
\cvtag{ Databricks}

\divider
\cvsubsection{Web Scraping}
\cvtag{ selenium}
\cvtag{ requests}
\cvtag{ BeautifulSoup4}



\cvsection{Langues}

\cvskill{\large Arabe}{5}
\cvskill{\large Anglais}{5}
\cvskill{\large Français}{5}


\cvsection{Certifications}

\cvachievement{\faGraduationCap}{\href{https://www.coursera.org/account/accomplishments/specialization/6XMVEAR45K6G}{Machine Learning Engineering for Production (MLOps)}}{\cvpart{DeepLearning.AI}\cvpart{\faCalendar 2022 2022}}
\cvachievement{\faGraduationCap}{\href{https://www.coursera.org/account/accomplishments/specialization/G8MVU96LKELW}{Natural Language Processing}}{\cvpart{DeepLearning.AI}\cvpart{\faCalendar 2024 2024}}
\cvachievement{\faGraduationCap}{\href{https://www.coursera.org/account/accomplishments/specialization/J5FL39Y2CK4D}{Cloud-Native Development with OpenShift and Kubernetes Specialization}}{\cvpart{DeepLearning.AI}\cvpart{\faCalendar 2023 2023}}
\cvachievement{\faGraduationCap}{\href{https://www.coursera.org/account/accomplishments/certificate/ABFVM3MXBCJN}{Rust Fundamentals}}{\cvpart{Duke University}\cvpart{\faCalendar 2024 2024}}
\cvachievement{\faGraduationCap}{\href{https://www.coursera.org/account/accomplishments/certificate/XUB5Z5U3HF9C}{Rust for DevOps}}{\cvpart{Duke University}\cvpart{\faCalendar 2024 2024}}
\cvachievement{\faGraduationCap}{\href{https://www.coursera.org/account/accomplishments/certificate/4WPJZL5DER96}{Rust for LLMOps (Large Language Model Operations)}}{\cvpart{Duke University}\cvpart{\faCalendar 2024 2024}}
\cvachievement{\faGraduationCap}{\href{https://www.coursera.org/account/accomplishments/certificate/7X42H7MNSLC3}{DevOps, DataOps, MLOps}}{\cvpart{Duke University}\cvpart{\faCalendar 2024 2024}}
\cvachievement{\faGraduationCap}{\href{https://www.coursera.org/account/accomplishments/records/E9F3SJLMEFDL}{MLOps Tools: MLflow and Hugging Face}}{\cvpart{Duke University}\cvpart{\faCalendar 2023 2023}}
\cvachievement{\faGraduationCap}{\href{https://www.coursera.org/account/accomplishments/records/6ZK4EC55RSC6}{Introduction to Large Language Models}}{\cvpart{Google Cloud}\cvpart{\faCalendar 2023 2023}}
\cvachievement{\faGraduationCap}{\href{}{TOEIC Listening and Reading Test (Score 985/990)}}{\cvpart{ETS Global}\cvpart{\faCalendar 2018 2018}}

\end{paracol}

\end{document}